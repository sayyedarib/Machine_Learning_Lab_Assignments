{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5591fb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graphviz import Digraph\n",
    "import math\n",
    "import random\n",
    "\n",
    "col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'type']\n",
    "original_data = pd.read_csv(r\"./dataset/Iris.csv\", skiprows=1, header=None, names=col_names)\n",
    "\n",
    "# col_names = ['Holiday', 'Discount', 'Free Delivery', 'Purchase']\n",
    "# original_data = pd.read_csv(r\"./dataset/Purchase_new.csv\", skiprows=1, header=None, names=col_names)\n",
    "\n",
    "data = original_data.copy()\n",
    "data = data[data['type'] != 'Iris-setosa']\n",
    "data = pd.concat([data,original_data[original_data['type'] == 'Iris-setosa'].sample(frac=1/3,random_state=42)])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18519484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_0 <= 4.8 ? 0.4444444444444444\n",
      " left:['Iris-setosa']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "X_0 <= 4.9 ? 0.2916666666666667\n",
      " left:X_0 <= 4.8 ? 0.4444444444444444\n",
      "  left:['Iris-setosa']\n",
      "  right:['Iris-virginica']\n",
      " right:['Iris-versicolor']\n",
      "\n",
      "X_3 <= 1.7 ? 0.34333333333333327\n",
      " left:X_0 <= 4.9 ? 0.2916666666666667\n",
      "  left:X_0 <= 4.8 ? 0.4444444444444444\n",
      "    left:['Iris-setosa']\n",
      "    right:['Iris-virginica']\n",
      "  right:['Iris-versicolor']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Final Tree:\n",
      "\n",
      "Visualizing Final Tree...\n",
      "\n",
      "X_0 <= 4.4 ? 0.19753086419753085\n",
      " left:['Iris-setosa']\n",
      " right:['Iris-versicolor']\n",
      "\n",
      "X_0 <= 5.9 ? 0.07438016528925631\n",
      " left:['Iris-virginica']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "X_3 <= 1.6 ? 0.3652020202020201\n",
      " left:X_0 <= 4.4 ? 0.19753086419753085\n",
      "  left:['Iris-setosa']\n",
      "  right:['Iris-versicolor']\n",
      " right:X_0 <= 5.9 ? 0.07438016528925631\n",
      "  left:['Iris-virginica']\n",
      "  right:['Iris-virginica']\n",
      "\n",
      "Final Tree:\n",
      "\n",
      "Visualizing Final Tree...\n",
      "\n",
      "X_1 <= 3.3 ? 0.14201183431952646\n",
      " left:['Iris-versicolor']\n",
      " right:['Iris-setosa']\n",
      "\n",
      "X_2 <= 4.7 ? 0.4226923076923078\n",
      " left:X_1 <= 3.3 ? 0.14201183431952646\n",
      "  left:['Iris-versicolor']\n",
      "  right:['Iris-setosa']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Final Tree:\n",
      "\n",
      "Visualizing Final Tree...\n",
      "\n",
      "X_2 <= 1.6 ? 0.47337278106508873\n",
      " left:['Iris-setosa']\n",
      " right:['Iris-versicolor']\n",
      "\n",
      "X_2 <= 4.8 ? 0.3473076923076923\n",
      " left:X_2 <= 1.6 ? 0.47337278106508873\n",
      "  left:['Iris-setosa']\n",
      "  right:['Iris-versicolor']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Final Tree:\n",
      "\n",
      "Visualizing Final Tree...\n",
      "\n",
      "Final Tree:\n",
      "\n",
      "Visualizing Final Tree...\n",
      "\n",
      "Training data: \n",
      "[[5.  3.6 1.4 0.2]\n",
      " [6.3 3.3 6.  2.5]]\n",
      "\n",
      "[['Iris-setosa']\n",
      " ['Iris-virginica']]\n",
      "Model 1 Metrics:\n",
      "Accuracy: 0.8\n",
      "Precision: 0.8530612244897959\n",
      "Recall: 0.8\n",
      "F1 Score: 0.7904761904761904\n",
      "\n",
      "Training data: \n",
      "[[5.  3.6 1.4 0.2]\n",
      " [6.3 3.3 6.  2.5]]\n",
      "\n",
      "[['Iris-setosa']\n",
      " ['Iris-virginica']]\n",
      "Model 2 Metrics:\n",
      "Accuracy: 0.7428571428571429\n",
      "Precision: 0.8530612244897959\n",
      "Recall: 0.7428571428571429\n",
      "F1 Score: 0.7092028660994179\n",
      "\n",
      "Training data: \n",
      "[[5.  3.6 1.4 0.2]\n",
      " [6.3 3.3 6.  2.5]]\n",
      "\n",
      "[['Iris-setosa']\n",
      " ['Iris-virginica']]\n",
      "Model 3 Metrics:\n",
      "Accuracy: 0.8571428571428571\n",
      "Precision: 0.8816806722689076\n",
      "Recall: 0.8571428571428571\n",
      "F1 Score: 0.8426551226551227\n",
      "\n",
      "Training data: \n",
      "[[5.  3.6 1.4 0.2]\n",
      " [6.3 3.3 6.  2.5]]\n",
      "\n",
      "[['Iris-setosa']\n",
      " ['Iris-virginica']]\n",
      "Model 4 Metrics:\n",
      "Accuracy: 0.9714285714285714\n",
      "Precision: 0.9731092436974791\n",
      "Recall: 0.9714285714285714\n",
      "F1 Score: 0.9712403538490495\n",
      "\n",
      "Training data: \n",
      "[[5.  3.6 1.4 0.2]\n",
      " [6.3 3.3 6.  2.5]]\n",
      "\n",
      "[['Iris-setosa']\n",
      " ['Iris-virginica']]\n",
      "Model 5 Metrics:\n",
      "Accuracy: 0.2\n",
      "Precision: 0.04\n",
      "Recall: 0.2\n",
      "F1 Score: 0.06666666666666667\n",
      "\n",
      "\n",
      "Aggregated Predictions: [array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-setosa'], dtype='<U11'), array(['Iris-setosa'], dtype='<U11'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-setosa'], dtype='<U11'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-setosa'], dtype='<U11'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-setosa'], dtype='<U11'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-setosa'], dtype='<U11'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-virginica'], dtype='<U14')]\n",
      "\n",
      "Accuracy: 0.8857142857142857\n",
      "Precision: 0.9142857142857143\n",
      "Recall: 0.8857142857142857\n",
      "F1 Score: 0.8883451523845611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/zulip-py3-venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_2 <= 1.6 ? 0.4970414201183432\n",
      " left:['Iris-setosa']\n",
      " right:['Iris-versicolor']\n",
      "\n",
      "X_0 <= 6.1 ? 0.34192307692307694\n",
      " left:X_2 <= 1.6 ? 0.4970414201183432\n",
      "  left:['Iris-setosa']\n",
      "  right:['Iris-versicolor']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Final Tree:\n",
      "X_0 <= 6.1 ? 0.34192307692307694\n",
      " left:X_2 <= 1.6 ? 0.4970414201183432\n",
      "  left:['Iris-setosa']\n",
      "  right:['Iris-versicolor']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Visualizing Final Tree...\n",
      "X_2 <= 1.5 ? 0.3550295857988165\n",
      " left:['Iris-setosa']\n",
      " right:['Iris-versicolor']\n",
      "\n",
      "X_2 <= 4.9 ? 0.37423076923076926\n",
      " left:X_2 <= 1.5 ? 0.3550295857988165\n",
      "  left:['Iris-setosa']\n",
      "  right:['Iris-versicolor']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Final Tree:\n",
      "X_2 <= 4.9 ? 0.37423076923076926\n",
      " left:X_2 <= 1.5 ? 0.3550295857988165\n",
      "  left:['Iris-setosa']\n",
      "  right:['Iris-versicolor']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Visualizing Final Tree...\n",
      "X_1 <= 2.2 ? 0.17999999999999994\n",
      " left:['Iris-virginica']\n",
      " right:['Iris-versicolor']\n",
      "\n",
      "X_2 <= 1.6 ? 0.2527777777777778\n",
      " left:['Iris-setosa']\n",
      " right:X_1 <= 2.2 ? 0.17999999999999994\n",
      "  left:['Iris-virginica']\n",
      "  right:['Iris-versicolor']\n",
      "\n",
      "X_3 <= 1.6 ? 0.34333333333333327\n",
      " left:X_2 <= 1.6 ? 0.2527777777777778\n",
      "  left:['Iris-setosa']\n",
      "  right:X_1 <= 2.2 ? 0.17999999999999994\n",
      "    left:['Iris-virginica']\n",
      "    right:['Iris-versicolor']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Final Tree:\n",
      "X_3 <= 1.6 ? 0.34333333333333327\n",
      " left:X_2 <= 1.6 ? 0.2527777777777778\n",
      "  left:['Iris-setosa']\n",
      "  right:X_1 <= 2.2 ? 0.17999999999999994\n",
      "    left:['Iris-virginica']\n",
      "    right:['Iris-versicolor']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Visualizing Final Tree...\n",
      "X_3 <= 1.6 ? 0.5\n",
      " left:['Iris-versicolor']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Final Tree:\n",
      "X_3 <= 1.6 ? 0.5\n",
      " left:['Iris-versicolor']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Visualizing Final Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/zulip-py3-venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_0 <= 4.9 ? 0.40816326530612246\n",
      " left:['Iris-setosa']\n",
      " right:['Iris-versicolor']\n",
      "\n",
      "X_3 <= 1.7 ? 0.3979591836734694\n",
      " left:X_0 <= 4.9 ? 0.40816326530612246\n",
      "  left:['Iris-setosa']\n",
      "  right:['Iris-versicolor']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Final Tree:\n",
      "X_3 <= 1.7 ? 0.3979591836734694\n",
      " left:X_0 <= 4.9 ? 0.40816326530612246\n",
      "  left:['Iris-setosa']\n",
      "  right:['Iris-versicolor']\n",
      " right:['Iris-virginica']\n",
      "\n",
      "Visualizing Final Tree...\n",
      "Training data: \n",
      "[[6.2 2.8 4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.8 2.8 5.1 2.4]]\n",
      "\n",
      "[['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-setosa']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-setosa']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']]\n",
      "Model 1 Metrics:\n",
      "Accuracy: 0.8\n",
      "Precision: 0.8530612244897959\n",
      "Recall: 0.8\n",
      "F1 Score: 0.7904761904761904\n",
      "\n",
      "Training data: \n",
      "[[6.2 2.8 4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.8 2.8 5.1 2.4]]\n",
      "\n",
      "[['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-setosa']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-setosa']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']]\n",
      "Model 2 Metrics:\n",
      "Accuracy: 0.7428571428571429\n",
      "Precision: 0.8530612244897959\n",
      "Recall: 0.7428571428571429\n",
      "F1 Score: 0.7092028660994179\n",
      "\n",
      "Training data: \n",
      "[[6.2 2.8 4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.8 2.8 5.1 2.4]]\n",
      "\n",
      "[['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-setosa']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-setosa']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']]\n",
      "Model 3 Metrics:\n",
      "Accuracy: 0.8571428571428571\n",
      "Precision: 0.8816806722689076\n",
      "Recall: 0.8571428571428571\n",
      "F1 Score: 0.8426551226551227\n",
      "\n",
      "Training data: \n",
      "[[6.2 2.8 4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.8 2.8 5.1 2.4]]\n",
      "\n",
      "[['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-setosa']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-setosa']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']]\n",
      "Model 4 Metrics:\n",
      "Accuracy: 0.9714285714285714\n",
      "Precision: 0.9731092436974791\n",
      "Recall: 0.9714285714285714\n",
      "F1 Score: 0.9712403538490495\n",
      "\n",
      "Training data: \n",
      "[[6.2 2.8 4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.7 3.  5.  1.7]\n",
      " [5.8 2.8 5.1 2.4]]\n",
      "\n",
      "[['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-setosa']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']\n",
      " ['Iris-virginica']\n",
      " ['Iris-setosa']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']\n",
      " ['Iris-versicolor']\n",
      " ['Iris-virginica']]\n",
      "Model 5 Metrics:\n",
      "Accuracy: 0.2\n",
      "Precision: 0.04\n",
      "Recall: 0.2\n",
      "F1 Score: 0.06666666666666667\n",
      "\n",
      "\n",
      "Aggregated Predictions: [array(['Iris-versicolor'], dtype='<U15'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-setosa'], dtype='<U11'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-setosa'], dtype='<U11'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-virginica'], dtype='<U14'), array(['Iris-versicolor'], dtype='<U15'), array(['Iris-setosa'], dtype='<U11')]\n",
      "\n",
      "Accuracy: 0.9565217391304348\n",
      "Precision: 0.9604743083003953\n",
      "Recall: 0.9565217391304348\n",
      "F1 Score: 0.95641277105808\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        self.value = value\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        self.root = None\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.dot = Digraph(comment='Decision Tree')\n",
    "\n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        X, Y = np.array([row[:-1] for row in dataset]), np.array([row[-1] for row in dataset])\n",
    "        num_samples, num_features = self.shape(X)\n",
    "\n",
    "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            if best_split[\"info_gain\"] > 0:\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth + 1)\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth + 1)\n",
    "                node = Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "                \n",
    "                self.print_tree(node)\n",
    "                print()\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "                \n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = np.array([row[feature_index] for row in dataset])\n",
    "            possible_thresholds = self.unique(feature_values)\n",
    "            for threshold in possible_thresholds:\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
    "                    y, left_y, right_y = np.array([row[-1] for row in dataset]), np.array([row[-1] for row in dataset_left]), np.array([row[-1] for row in dataset_right])\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    if curr_info_gain > max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "        return best_split\n",
    "\n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        dataset_left = [row for row in dataset if row[feature_index] <= threshold]\n",
    "        dataset_right = [row for row in dataset if row[feature_index] > threshold]\n",
    "        return dataset_left, dataset_right\n",
    "\n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if mode == \"gini\":\n",
    "            gain = self.gini_index(parent) - (weight_l * self.gini_index(l_child) + weight_r * self.gini_index(r_child))\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (weight_l * self.entropy(l_child) + weight_r * self.entropy(r_child))\n",
    "        return gain\n",
    "\n",
    "    def entropy(self, y):\n",
    "        class_labels = self.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len([label for label in y if label == cls]) / len(y)\n",
    "            entropy += -p_cls * self.log2(p_cls)\n",
    "        return entropy\n",
    "\n",
    "    def gini_index(self, y):\n",
    "        class_labels = self.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len([label for label in y if label == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "\n",
    "    def calculate_leaf_value(self, Y):\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "\n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\" + str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        dataset = X.tolist()\n",
    "        for i, y in enumerate(Y):\n",
    "            dataset[i].append(y)\n",
    "        self.root = self.build_tree(dataset)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return predictions\n",
    "\n",
    "    def make_prediction(self, x, tree):\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val <= tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)\n",
    "\n",
    "    def shape(self, array):\n",
    "        return len(array), len(array[0])\n",
    "\n",
    "    def unique(self, array):\n",
    "        return np.unique(array)\n",
    "\n",
    "    def log2(self, x):\n",
    "        return 0 if x == 0 else math.log2(x)\n",
    "\n",
    "    def visualize_tree(self, tree=None):\n",
    "        global counter\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            self.dot.node(str(id(tree)), str(tree.value), shape='oval', style='filled', color='lightblue')\n",
    "\n",
    "        else:\n",
    "            filename = f'tree_{counter}'\n",
    "            self.dot.node(str(id(tree)), f'X_{str(tree.feature_index)} <= {str(tree.threshold)}\\nInfo Gain: {str(tree.info_gain)}', shape='box', style='filled', color='lightgreen')\n",
    "            if tree.left:\n",
    "                self.dot.edge(str(id(tree)), str(id(tree.left)), label='True')\n",
    "                self.visualize_tree(tree.left)\n",
    "            if tree.right:\n",
    "                self.dot.edge(str(id(tree)), str(id(tree.right)), label='False')\n",
    "                self.visualize_tree(tree.right)\n",
    "\n",
    "            self.dot.render(filename, view=True)\n",
    "            counter += 1 \n",
    "\n",
    "\n",
    "    def save_tree_graph(self, filename=None):\n",
    "        global counter\n",
    "        if filename is None:\n",
    "            filename = f'decision_tree_{counter}'\n",
    "        self.visualize_tree()\n",
    "        self.dot.render(filename, view=True)\n",
    "        counter += 1 \n",
    "\n",
    "    def visualize_intermediate_trees(self):\n",
    "        for depth in range(1, self.max_depth + 1):\n",
    "            classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=depth)\n",
    "            classifier.fit(X_train, Y_train)\n",
    "            classifier.visualize_tree()\n",
    "            # classifier.save_tree_graph()\n",
    "            print(f\"Visualizing Intermediate Tree (Depth {depth})...\")\n",
    "\n",
    "\n",
    "def split(X, y, test_size):\n",
    "    data = list(zip(X, y))\n",
    "    num_samples = len(data)\n",
    "    num_test_samples = int(num_samples * test_size)\n",
    "    num_train_samples = num_samples - num_test_samples\n",
    "    random.shuffle(data)\n",
    "    train_data = data[:num_train_samples]\n",
    "    test_data = data[num_train_samples:]\n",
    "    X_train, y_train = zip(*train_data)\n",
    "    X_test, y_test = zip(*test_data)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    correct = sum(1 for true, pred in zip(y_true, y_pred) if true == pred)\n",
    "    return correct / len(y_true)\n",
    "\n",
    "\n",
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values.reshape(-1, 1)\n",
    "X_train, Y_train, X_test, Y_test = split(X, Y, test_size=0.3)\n",
    "\n",
    "X_train\n",
    "\n",
    "Y_train\n",
    "\n",
    "num_models = 5\n",
    "models = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "for i in range(num_models):\n",
    "    start_idx = i * 20\n",
    "    end_idx = (i + 1) * 20\n",
    "    X_train_subset = np.array(X_train[start_idx:end_idx])\n",
    "    Y_train_subset = np.array(Y_train[start_idx:end_idx])\n",
    "\n",
    "    classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
    "    classifier.fit(X_train_subset, Y_train_subset)\n",
    "\n",
    "    Y_pred = classifier.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "    recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "    f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "\n",
    "    models.append(classifier)\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(\"Final Tree:\")\n",
    "    # classifier.print_tree()\n",
    "    print()\n",
    "    print(\"Visualizing Final Tree...\")\n",
    "    # classifier.save_tree_graph()\n",
    "    print()\n",
    "\n",
    "for i in range(num_models):\n",
    "    print(\"Training data: \")\n",
    "    print(X_train_subset)\n",
    "    print()\n",
    "    print(Y_train_subset)\n",
    "    print(f\"Model {i + 1} Metrics:\")\n",
    "    print(f\"Accuracy: {accuracies[i]}\")\n",
    "    print(f\"Precision: {precisions[i]}\")\n",
    "    print(f\"Recall: {recalls[i]}\")\n",
    "    print(f\"F1 Score: {f1_scores[i]}\")\n",
    "    print()\n",
    "\n",
    "def aggregate_predictions(models, X_test, Y_test):\n",
    "    num_models = len(models)\n",
    "    aggregated_predictions = []\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        individual_predictions = [model.predict([X_test[i]])[0] for model in models]\n",
    "        \n",
    "        counts = {}\n",
    "        for prediction in individual_predictions:\n",
    "            prediction_tuple = tuple(prediction)\n",
    "            if prediction_tuple in counts:\n",
    "                counts[prediction_tuple] += 1\n",
    "            else:\n",
    "                counts[prediction_tuple] = 1\n",
    "        aggregated_prediction_tuple = max(counts, key=counts.get)\n",
    "        aggregated_prediction = np.array(aggregated_prediction_tuple)\n",
    "\n",
    "        aggregated_predictions.append(aggregated_prediction)\n",
    "\n",
    "#         print(f\"Sample {i + 1} - Individual Predictions: {individual_predictions}, Actual Value: {Y_test[i][0]}, Aggregated Prediction: {aggregated_prediction[0]}\")\n",
    "\n",
    "    accuracy = sum(1 for p, y in zip(aggregated_predictions, Y_test) if np.array_equal(p, y)) / len(Y_test)\n",
    "    precision = precision_score(Y_test, aggregated_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(Y_test, aggregated_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(Y_test, aggregated_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "    print(\"\\nAggregated Predictions:\", aggregated_predictions)\n",
    "    print(\"\\nAccuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "aggregate_predictions(models, X_test, Y_test)\n",
    "\n",
    "\n",
    "X_train_2, Y_train_2, X_test_2, Y_test_2 = split(X, Y, test_size=0.2)\n",
    "\n",
    "for i in range(num_models):\n",
    "    start_idx = i * 20\n",
    "    end_idx = (i + 1) * 20\n",
    "    X_train_subset = np.array(X_train_2[start_idx:end_idx])\n",
    "    Y_train_subset = np.array(Y_train_2[start_idx:end_idx])\n",
    "\n",
    "    classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
    "    classifier.fit(X_train_subset, Y_train_subset)\n",
    "\n",
    "    Y_pred_2 = classifier.predict(X_test_2)\n",
    "\n",
    "    accuracy_2 = accuracy_score(Y_test_2, Y_pred_2)\n",
    "    precision_2 = precision_score(Y_test_2, Y_pred_2, average='weighted')\n",
    "    recall_2= recall_score(Y_test_2, Y_pred_2, average='weighted')\n",
    "    f1_2 = f1_score(Y_test_2, Y_pred_2, average='weighted')\n",
    "\n",
    "    models.append(classifier)\n",
    "    accuracies.append(accuracy_2)\n",
    "    precisions.append(precision_2)\n",
    "    recalls.append(recall_2)\n",
    "    f1_scores.append(f1_2)\n",
    "\n",
    "    print(\"Final Tree:\")\n",
    "    classifier.print_tree()\n",
    "    print()\n",
    "    print(\"Visualizing Final Tree...\")\n",
    "    classifier.save_tree_graph()\n",
    "\n",
    "for i in range(num_models):\n",
    "    print(\"Training data: \")\n",
    "    print(X_train_subset)\n",
    "    print()\n",
    "    print(Y_train_subset)\n",
    "    print(f\"Model {i + 1} Metrics:\")\n",
    "    print(f\"Accuracy: {accuracies[i]}\")\n",
    "    print(f\"Precision: {precisions[i]}\")\n",
    "    print(f\"Recall: {recalls[i]}\")\n",
    "    print(f\"F1 Score: {f1_scores[i]}\")\n",
    "    print()\n",
    "    \n",
    "def aggregate_predictions(models, X_test_2, Y_test_2):\n",
    "    num_models_2 = len(models)\n",
    "    aggregated_predictions_2 = []\n",
    "\n",
    "    for i in range(len(X_test_2)):\n",
    "        individual_predictions_2 = [model.predict([X_test_2[i]])[0] for model in models]\n",
    "        \n",
    "        counts = {}\n",
    "        for prediction in individual_predictions_2:\n",
    "            prediction_tuple = tuple(prediction)\n",
    "            if prediction_tuple in counts:\n",
    "                counts[prediction_tuple] += 1\n",
    "            else:\n",
    "                counts[prediction_tuple] = 1\n",
    "        aggregated_prediction_tuple = max(counts, key=counts.get)\n",
    "        aggregated_prediction = np.array(aggregated_prediction_tuple)\n",
    "\n",
    "        aggregated_predictions_2.append(aggregated_prediction)\n",
    "\n",
    "    accuracy = sum(1 for p, y in zip(aggregated_predictions_2, Y_test_2) if np.array_equal(p, y)) / len(Y_test_2)\n",
    "    precision = precision_score(Y_test_2, aggregated_predictions_2, average='weighted', zero_division=0)\n",
    "    recall = recall_score(Y_test_2, aggregated_predictions_2, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(Y_test_2, aggregated_predictions_2, average='weighted', zero_division=0)\n",
    "\n",
    "    print(\"\\nAggregated Predictions:\", aggregated_predictions_2)\n",
    "    print(\"\\nAccuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "aggregate_predictions(models, X_test_2, Y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe7ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Load the Iris dataset\n",
    "# col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'type']\n",
    "# data = pd.read_csv(r\"./dataset/Iris.csv\", skiprows=1, header=None, names=col_names)\n",
    "\n",
    "# # Choose the class to under-sample (e.g., 'Iris-setosa')\n",
    "# class_to_under_sample = 'Iris-setosa'\n",
    "\n",
    "# # Set the desired imbalance ratio (e.g., 1:3 for the chosen class)\n",
    "# imbalance_ratio = 3\n",
    "\n",
    "# # Randomly under-sample the chosen class\n",
    "# data_imbalanced = data.copy()\n",
    "# data_imbalanced = data_imbalanced[data_imbalanced['type'] != class_to_under_sample]\n",
    "# data_imbalanced = pd.concat([\n",
    "#     data_imbalanced,\n",
    "#     data[data['type'] == class_to_under_sample].sample(\n",
    "#         frac=1/imbalance_ratio,\n",
    "#         random_state=42  # You can change the random state for reproducibility\n",
    "#     )\n",
    "# ])\n",
    "\n",
    "# # Print the class distribution in the imbalanced dataset\n",
    "# print(data_imbalanced['type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5804c180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
